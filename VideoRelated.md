# Table of Contents
- [Video Super Resolution](#video-super-resolution)
- [Frame Interpolation](#frame-interpolation)
- [Video Enhancement & Restoration](#video-enhancement-and-restoration)
- [Video Stabilization](#video-stabilization)
- [Video Debluring](#video-debluring)
- [Video Deraining](#video-deraining)
- [Video Dehazing](#video-dehazing)
- [Video Matting](#video-matting)
- [Video Inpainting](#video-inpainting)
- [Video Synthesis](#video-synthesis)
- [Video Editing](#video-editing)
- [Misc](#misc)


# Video Super Resolution
- **Learning Spatiotemporal Frequency-Transformer for Compressed Video Super-Resolution**  <Br>
Zhongwei Qiu, [Huan Yang(https://www.microsoft.com/en-us/research/people/huayan/publications/), Jianlong Fu, Dongmei Fu <Br>
[ECCV 2022] [[Pytorch-Code](https://github.com/researchmm/FTVSR)] <Br>
[**FTVSR**]

- **Towards Interpretable Video Super-Resolution via Alternating Optimization**  <Br>
[Jiezhang Cao](https://www.jiezhangcao.com/), [Jingyun Liang](https://jingyunliang.github.io/), [Kai Zhang](https://cszn.github.io/), [Wenguan Wang](http://homepage.hit.edu.cn/wangmengzuo), [Qin Wang](https://www.qin.ee/zh/), [Yulun Zhang](https://yulunzhang.com/), [Hao Tang](http://disi.unitn.it/~hao.tang/), [Luc Van Gool](https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html) <Br>
[ECCV 2022] [[Pytorch-Code](https://github.com/caojiezhang/DAVSR)] <Br>

- **AnimeSR: Learning Real-World Super-Resolution Models for Animation Videos**  <Br>
Yanze Wu, [Xintao Wang](https://xinntao.github.io/), Gen Li, Ying Shan <Br>
[arXiv 2206]  <Br>
[â˜…â˜†] æå‡ºäº†ä¸€ä¸ªé«˜æ¸…åŠ¨ç”»æ•°æ®é›†. æå‡ºäº†ä¸€ä¸ªå­¦ä¹ learnable basic operatorçš„æµç¨‹, è¯¥ç®—å­å¯ä»¥åŠ å…¥åˆ°é€€åŒ–æµç¨‹ä¸­ç”Ÿæˆæ›´çœŸå®çš„LRæ ·æœ¬.

- **Real-RawVSR: Real-World Raw Video Super-Resolution with a Benchmark Dataset**  <Br>
[Jiyang Yu](http://jiyang.fun/), Jingen Liu, [Liefeng Bo](https://research.cs.washington.edu/istc/lfb/), [Tao Mei](https://taomei.me/) <Br>
[ECCV 2022] [[Pytorch-Code](https://github.com/zmzhang1998/Real-RawVSR)] <Br>
[â˜…â˜†] æ”¶é›†äº†ä¸€ä¸ªçœŸå®çš„HR/LRæ•°æ®é›†, é€šè¿‡beam-splitterå’Œä¸¤ä¸ªç›¸æœºæ”¶é›†LR, HR, ç”¨å…¨å±€å’Œå±€éƒ¨çš„å¯¹é½å°†HRå¯¹é½åˆ°LRä¸Š.

- **Memory-Augmented Non-Local Attention for Video Super-Resolution**  <Br>
[Jiyang Yu](http://jiyang.fun/), Jingen Liu, [Liefeng Bo](https://research.cs.washington.edu/istc/lfb/), [Tao Mei](https://taomei.me/) <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/jiy173/MANA)] <Br>

- **VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution**  <Br>
[Zeyuan Chen](http://zeyuan-chen.com/), [Yinbo Chen](https://yinboc.github.io/), Jingwen Liu, Xingqian Xu, [Vidit Goel](https://vidit98.github.io/), Zhangyang Wang, [Humphrey Shi](https://www.humphreyshi.com/), [Xiaolong Wang](https://xiaolonw.github.io/) <Br>
[CVPR 2022] [[Project](http://zeyuan-chen.com/VideoINR/)] [[Pytorch-Code](https://github.com/Picsart-AI-Research/VideoINR-Continuous-Space-Time-Super-Resolution)] <Br>

- **Learning Trajectory-Aware Transformer for Video Super-Resolution** <Br>
Chengxu Liu, [Huan Yang](https://www.microsoft.com/en-us/research/people/huayan/), [Jianlong Fu](https://www.microsoft.com/en-us/research/people/jianf/), [Xueming Qian](http://smiles.xjtu.edu.cn/) <Br>
[CVPR 2022 Oral] [[Pytorch-Code](https://github.com/researchmm/TTVSR)] <Br>
[**TTVSR**]

- **Reference-based Video Super-Resolution Using Multi-Camera Video Triplets**  <Br>
[Junyong Lee](https://junyonglee.me/), Myeonghee Lee, [Sunghyun Cho](https://www.scho.pe.kr/), [Seungyong Lee](http://cg.postech.ac.kr/leesy/) <Br>
[CVPR 2022] [[Project](https://junyonglee.me/projects/RefVSR/)] [[Pytorch-Code](https://github.com/codeslake/RefVSR)] <Br>
	
- **Investigating Tradeoffs in Real-World Video Super-Resolution** <Br>
[Kelvin C.K. Chan](https://ckkelvinchan.github.io/), [Shangchen Zhou](https://shangchenzhou.com/), [Xiangyu Xu](https://sites.google.com/view/xiangyuxu), [Chen Change Loy](http://personal.ie.cuhk.edu.hk/~ccloy/) <Br>
[CVPR 2022]  [[Pytorch-Code](https://github.com/ckkelvinchan/RealBasicVSR)] <Br>
[**RealBasicVSR**]

- **Real-Time Super-Resolution System of 4K-Video Based on Deep Learning** <Br>
Yanpeng Cao, Chengcheng Wang, Changjun Song, Yongming Tang, He Li <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/Thmen/EGVSR)] <Br>
[**EGVSR**] [â˜…â˜†] å¿«é€Ÿè§†é¢‘è¶…åˆ†ç½‘ç»œ, æ¨¡å‹å’Œlosså‚è€ƒäº†TecoGAN

- **Video Super-Resolution Transformer** <Br>
[Jiezhang Cao](https://www.jiezhangcao.com/), [Yawei Li](https://yaweili.bitbucket.io/), [Kai Zhang](https://cszn.github.io/), [Luc Van Gool](https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html) <Br>
[arXiv 2106] [[Pytorch-Code](https://github.com/caojiezhang/VSR-Transformer)] <Br>

- **BasicVSR++: Improving Video Super-Resolution with Enhanced Propagation and Alignment** <Br>
[Kelvin C.K. Chan](https://ckkelvinchan.github.io/), [Shangchen Zhou](https://shangchenzhou.com/), [Xintao Wang](https://xinntao.github.io/), [Chen Change Loy](http://personal.ie.cuhk.edu.hk/~ccloy/) <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/open-mmlab/mmediting)] <Br>
[â˜…] åœ¨BasicVSRçš„åŸºç¡€ä¸Š, ä½¿ç”¨åå¤å‰å‘åå‘ä¼ æ’­çš„ç»“æ„å’Œflow-guided deformable alignment, æå‡äº†æ€§èƒ½

- **DynaVSR: Dynamic Adaptive Blind VideoSuper-Resolution** <Br>
Suyoung Lee, [Myungsub Choi](https://myungsub.github.io/), [Kyoung Mu Lee](https://cv.snu.ac.kr/index.php/~kmlee/)   <Br>
[WACV 2021] [[Project](https://ckkelvinchan.github.io/projects/DCN/)] [[Pytorch-Code](https://github.com/ckkelvinchan/offset-fidelity-loss)] <Br>

- **Understanding Deformable Alignment in Video Super-Resolution** <Br>
[Kelvin C.K. Chan](https://ckkelvinchan.github.io/), [Xintao Wang](https://xinntao.github.io/), [Ke Yu](https://yuke93.github.io/), Chao Dong, [Chen Change Loy](https://www.mmlab-ntu.com/person/ccloy/)   <Br>
[AAAI 2021] [[Project](https://ckkelvinchan.github.io/projects/DCN/)] [[Pytorch-Code](https://github.com/ckkelvinchan/offset-fidelity-loss)] <Br>
[**DCN**] [â˜…] åˆ†æäº†å¯å˜å½¢å·ç§¯å¯¹é½å’Œflow-basedå¯¹é½çš„ç›¸ä¼¼æ€§, æŒ‡å‡ºdeformable alignmentä¸­offsetçš„å¤šæ ·æ€§å¯¹VSRè¿™æ ·çš„ä»»åŠ¡æœ‰ä¼˜åŠ¿. å¦å¤–, æå‡ºäº†ä¸€ä¸ªoffset fidelity loss, ç”¨å…‰æµçº¦æŸoffsetçš„å­¦ä¹ .

- **Omniscient Video Super-Resolution** <Br>
Peng Yi, Zhongyuan Wang, [Kui Jiang](https://github.com/kuijiang0802/kuijiang0802.github.io/blob/master/home.md), [Junjun Jiang](http://homepage.hit.edu.cn/jiangjunjun), Tao Lu, Xin Tian, [Jiayi Ma](https://sites.google.com/view/jiayima) <Br>
[ICCV 2021] [[Pytorch-Code](https://github.com/psychopa4/OVSR)]<Br>
[**OVSR**]

- **Deep Blind Video Super-resolution** <Br>
 [Jinshan Pan](https://jspan.github.io/), [Haoran Bai](https://csbhr.github.io/), Jiangxin Dong, Jiawei Zhang, Jinhui Tang <Br>
[ICCV 2021] [[Pytorch-Code](https://github.com/csbhr/Deep-Blind-VSR)]<Br>
	
- **COMISR:Compression-Informed Video Super-Resolution** <Br>
Yinxiao Li, [Pengchong Jin](https://research.google/people/PengchongJin/), [Feng Yang](https://sites.google.com/view/feng-yang), [Ce Liu](http://people.csail.mit.edu/celiu/), [Ming-Hsuan Yang](https://faculty.ucmerced.edu/mhyang/), [Peyman Milanfar](https://sites.google.com/view/milanfarhome/)   <Br>
[ICCV 2021] [[TF2-Code](https://github.com/google-research/google-research/tree/master/comisr)]<Br>

- **Space-Time Distillation for Video Super-Resolution** <Br>
Zeyu Xiao, [Xueyang Fu](https://xueyangfu.github.io/), Jie Huang, Zhen Cheng, Zhiwei Xiong <Br>
[CVPR 2021] <Br>
[**STD**] [â˜…] åˆ†ä¸ºç©ºé—´å’Œæ—¶é—´è’¸é¦ä¸¤éƒ¨åˆ†. ç©ºé—´è’¸é¦é€šè¿‡è®©Så’ŒTçš„ç©ºé—´attention mapæ¥è¿‘æ¥è®­ç»ƒ. æ—¶é—´è’¸é¦ä½¿ç”¨ConvLSTMæå–æ—¶é—´ç‰¹å¾, ç›‘ç£è¯¥ç‰¹å¾è®­ç»ƒ.

- **Video Rescaling Networks with Joint Optimization Strategies for Downscaling and Upscaling** <Br>
 [Yan-Cheng Huang](https://www.linkedin.com/in/hyancheng96),  [Yi-Hsin Chen](mailto:yhchen12101@gmail.com),  [Cheng-You Lu](https://johnnylu305.github.io), [Hui-Po Wang](https://a514514772.github.io), [Wen-Hsiao Peng](https://sites.google.com/g2.nctu.edu.tw/wpeng/cv), [Ching-Chun Huang](http://acm.cs.nctu.edu.tw/Home.aspx)   <Br>
[CVPR 2021] [[Project](https://ding3820.github.io/MIMO-VRN/)] [[Pytorch-Code](https://github.com/ding3820/MIMO-VRN)]<Br>
[**MIMO-VRN**]

- **BasicVSR: The Search for Essential Components in Video Super-Resolution and Beyond** <Br>
[Kelvin C.K. Chan](https://ckkelvinchan.github.io/), [Xintao Wang](https://xinntao.github.io/), [Ke Yu](https://yuke93.github.io/), [Chao Dong](https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ&hl=zh-CN), [Chen Change Loy](http://personal.ie.cuhk.edu.hk/~ccloy/) <Br>
[CVPR 2021] [[Project](https://ckkelvinchan.github.io/projects/BasicVSR/)] [[Pytorch-Code](https://github.com/ckkelvinchan/BasicVSR-IconVSR)]<Br>
[â˜…â˜†] å°†è§†é¢‘è¶…åˆ†åˆ†è§£ä¸ºpropagation, alignment, aggregationå’Œupsamplingå››éƒ¨åˆ†. åœ¨æ­¤åŸºç¡€ä¸Šè®¾è®¡äº†BasicVSRç½‘ç»œ, ä»¥åŠåŠ å…¥äº†ä¸¤ä¸ªæ–°è®¾è®¡æ¨¡å—çš„IconVSR

- **Temporal Modulation Network for Controllable Space-Time Video Super-Resolution** <Br>
Gang Xu, [Jun Xu](https://csjunxu.github.io/), Zhen Li, Liang Wang, [Xing Sun](https://www.sunxing.org/), [Mingming Cheng](http://mmcheng.net/cmm/) <Br>
[CVPR 2021] [[Pytorch-Code](https://github.com/CS-GangXu/TMNet)]<Br>
[**TMNet**] [â˜…] ä½¿ç”¨ä¸€ä¸ªæ—¶é—´è°ƒåˆ¶æ¨¡å—, æ ¹æ®ä¸åŒçš„t, æ§åˆ¶deformable convçš„æ’å¸§ç»“æœ. è®¾è®¡äº†ä¸€ä¸ªfeature fusionæ¨¡å—, refineå±€éƒ¨è¿åŠ¨, ä½¿ç”¨åŒå‘å¯å˜å½¢å·ç§¯BDConvLSTM refineå…¨å±€è¿åŠ¨.

- **Real-Time Super-Resolution System of 4K-Video Based on Deep Learning** <Br>
Yanpeng Cao, Chengcheng Wang, Changjun Song, Yongming Tang, He Li <Br>
[arXiv 2107] [[Pytorch-Code](https://github.com/Thmen/EGVSR)]<Br>
[**EGVSR**] [â˜…â˜†] åŸºäºTecoGAN, è®¾è®¡äº†ä¸€ä¸ªè½»é‡çº§è§†é¢‘è¶…åˆ†æ¨¡å‹

- **Learning the Loss Functions in a Discriminative Space for Video Restoration** <Br>
[Younghyun Jo](https://yhjo09.github.io/), Jaeyeon Kang, Seoung Wug Oh, Seonghyeon Nam, Peter Vajda, [Seon Joo Kim](https://sites.google.com/view/seoungwugoh/) <Br>
[arXiv 2003] <Br>

- **ISR: Deep Joint Frame Interpolation and Super-Resolution with A Multi-scale Temporal Loss** <Br>
[Soo Ye Kim](https://sites.google.com/view/sooyekim),[Jihyong Oh](https://sites.google.com/view/ozbro/%ED%99%88), [Munchurl Kim](https://www.viclab.kaist.ac.kr/) <Br>
[AAAI 2020] [[TF-Code](https://github.com/JihyongOh/FISR)]<Br>
	
- **Space-Time-Aware Multi-Resolution Video Enhancement** <Br>
[Muhammad Haris](https://alterzero.github.io/), [Greg Shakhnarovich](https://ttic.uchicago.edu/~gregory/), [Norimichi Ukita](https://www.toyota-ti.ac.jp/Lab/Denshi/iim/ukita/)<Br>
[CVPR 2020] [[Project](https://alterzero.github.io/projects/STAR.html)] [[Pytorch-Code](https://github.com/alterzero/STARnet)]<Br>
[**STARnet**] [â˜…â˜…] æ—¶ç©ºè”åˆè¶…åˆ†
	
- **TDAN: Temporally-Deformable Alignment Network for Video Super-Resolution** <Br>
[Yapeng Tian](https://yapengtian.org/), [Yulun Zhang](http://yulunzhang.com/), [Yun Fu](http://www1.ece.neu.edu/~yunfu/), [Chenliang Xu](https://www.cs.rochester.edu/~cxu22/)<Br>
[CVPR 2020] [[Pytorch-Code](https://github.com/YapengTian/TDAN-VSR-CVPR-2020)]<Br>
[**TDAN**] [â˜…â˜†] ç”¨deformable convåšVSR
	
- **Fast and Accurate One-Stage Space-Time Video Super-Resolution** <Br>
 [Xiaoyu Xiang](https://engineering.purdue.edu/people/xiaoyu.xiang.1), [Yapeng Tian](http://yapengtian.org/), [Yulun Zhang](http://yulunzhang.com/), [Yun Fu](http://www1.ece.neu.edu/~yunfu/), [Jan P. Allebach](https://engineering.purdue.edu/~allebach/), [Chenliang Xu](https://www.cs.rochester.edu/~cxu22/) <Br>
[CVPR 2020]  [[Pytorch-Code](https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020)]<Br>
[**Zooming-Slow-M**] [â˜…â˜†] æ—¶ç©ºè”åˆè¶…åˆ†, åŸºäºdeformableå·ç§¯å’ŒConvLSTM

- **STVUN: Deep Space-Time Video Upsampling Networks** <Br>
Jaeyeon Kang, [Younghyun Jo](https://yhjo09.github.io/), [Seoung Wug Oh](https://sites.google.com/view/seoungwugoh), [Peter Vajda](https://sites.google.com/site/vajdap/), [Seon Joo Kim](https://sites.google.com/site/seonjookim/) <Br>
[ECCV 2020] [[Pytorch-Code](https://github.com/JaeYeonKang/STVUN-Pytorch)]<Br>	

- **Across Scales & Across Dimensions: Temporal Super-Resolution using Deep Internal Learning** <Br>
Liad Pollak Zuckerman, Eyal Naor, George Pisha, [Shai Bagon](https://www.weizmann.ac.il/math/bagon/), Michal Irani <Br>
[ECCV 2020] [[Project](http://www.wisdom.weizmann.ac.il/~vision/DeepTemporalSR/)] [[Pytorch-Code](https://github.com/eyalnaor/DeepTemporalSR)]<Br>	
[**DeepTemporalSR**]

- **MuCAN: Multi-Correspondence Aggregation Network for Video Super-Resolution** <Br>
Wenbo Li, [Xin Tao](http://www.xtao.website/), Taian Guo, [Lu Qi](http://luqi.info/), Jiangbo Lu, [Jiaya Jia](http://jiaya.me/) <Br>
[ECCV 2020] <Br>

- **Video Super-Resolution with Recurrent Structure-Detail Network** <Br>
Takashi Isobe, [Xu Jia](https://stephenjia.github.io/), [Shuhang Gu](https://sites.google.com/site/shuhanggu/), Songjiang Li, Shengjin Wang, Qi Tian<Br>
[ECCV 2020] [[Pytorch-Code](https://github.com/junpan19/RSDN)]<Br>
[**RSDN**]

- **Recurrent Back-Projection Network for Video Super-Resolution** <Br>
[Muhammad Haris](https://alterzero.github.io/), [Greg Shakhnarovich](https://ttic.uchicago.edu/~gregory/), [Norimichi Ukita](https://www.toyota-ti.ac.jp/Lab/Denshi/iim/ukita/) <Br>
[ECCV 2020] [[Project](https://alterzero.github.io/projects/RBPN.html)] [[Pytorch-Code](https://github.com/alterzero/RBPN-PyTorch)]<Br>
[**RBPN**] [â˜…â˜†] è§†é¢‘è¶…åˆ†, ä½¿ç”¨DBPNä¸­çš„back-projectionç»“æ„åˆ©ç”¨å‰nå¸§ä¿¡æ¯å®Œæˆå¯¹å½“å‰å¸§çš„ç©ºé—´è¶…åˆ†.

- **Learning Temporal Coherence via Self-Supervision for GAN-based Video Generation** <Br>
[Mengyu Chu](https://people.mpi-inf.mpg.de/~mchu/), You Xie, Laura Leal-Taixe, [Nils Thuerey](https://ge.in.tum.de/) <Br>
[SIGGRAPH 2020] [[TF-Code](https://github.com/thunil/TecoGAN)]<Br>
[**TecoGAN**] [â˜…â˜…] æå‡ºæ—¶ç©ºä¸€è‡´æ€§çš„GANå’Œä¸€ä¸ªping-pong lossä¿æŒlong termæ—¶é—´ä¸€è‡´æ€§
	
- **Efficient Video Super-Resolution through Recurrent Latent Space Propagation** <Br>
Dario Fuoli, [Shuhang Gu](https://shuhanggu.github.io/), [Radu Timofte](https://people.ee.ethz.ch/~timofter/) <Br>
[ICCVW 2019] [[Pytorch-Code](https://github.com/dariofuoli/RLSP)]<Br>
[**RLSP**] [â˜…] ç”¨RNNåšè§†é¢‘è¶…åˆ†, ä½¿ç”¨æ®‹å·®å’Œpixel shuffle.
	
- **Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation** <Br>
 [Younghyun Jo](https://yhjo09.github.io/), [Seoung Wug Oh](https://sites.google.com/view/seoungwugoh), Jaeyeon Kang, [Seon Joo Kim](https://sites.google.com/site/seonjookim/) <Br>
[CVPR 2018] [[Pytorch-Code](https://github.com/yhjo09/VSR-DUF0)]<Br>
[**DUF**]	
	
	
	
	
# Frame Interpolation
- **AMT: All-Pairs Multi-Field Transforms for Efficient Frame Interpolation** <Br>
[Zhen Li](https://paper99.github.io/), [Zuo-Liang Zhu](https://nk-cs-zzl.github.io/), Ling-Hao Han, [Qibin Hou](https://houqb.github.io/), Chun-Le Guo, [Ming-Ming Cheng](https://mmcheng.net/cmm/) <Br>
[CVPR 2023] [[Project](https://nk-cs-zzl.github.io/projects/amt/index.html)] [[Pytorch-Code](https://github.com/MCG-NKU/AMT)]<Br>

- **BiFormer: Learning Bilateral Motion Estimation via Bilateral Transformer for 4K Video Frame Interpolation** <Br>
Junheum Park, Jintae Kim, Chang-Su Kim<Br>
[CVPR 2023] [[Pytorch-Code](https://github.com/JunHeum/BiFormer)]<Br>

- **A Unified Pyramid Recurrent Network for Video Frame Interpolation** <Br>
Xin Jin, Longhai Wu, Jie Chen, Youxin Chen, Jayoon Koo, Cheul-hee Hahm <Br>
[CVPR 2023] [[Pytorch-Code](https://github.com/srcn-ivl/upr-net)]<Br>

- **Extracting Motion and Appearance via Inter-Frame Attention for Efficient Video Frame Interpolation** <Br>
Guozhen Zhang, Yuhan Zhu, Haonan Wang, Youxin Chen, [Gangshan Wu](http://mcg.nju.edu.cn/member/gswu/en/index.html), [Limin Wang](http://wanglimin.github.io/) <Br>
[CVPR 2023] [[Pytorch-Code](https://github.com/MCG-NJU/EMA-VFI)]<Br>
[**EMA-VFI**]

- **Beyond a Video Frame Interpolator: A Space Decoupled Learning Approach to Continuous Image Transition** <Br>
[Tao Yang](https://cg.cs.tsinghua.edu.cn/people/~tyang/), Peiran Ren, Xuansong Xie, Xiansheng Hua, [Lei Zhang](http://www4.comp.polyu.edu.hk/~cslzhang/) <Br>
[arXiv 2203] [[Pytorch-Code](https://github.com/yangxy/sdl)]<Br>
[**SDL**]

- **FILM: Frame Interpolation for Large Motion** <Br>
Fitsum Reda, Janne Kontkanen, [Eric Tabellion](http://www.tabellion.org/et/), [Deqing Sun](https://deqings.github.io/), Caroline Pantofaru, [Brian Curless](https://homes.cs.washington.edu/~curless/) <Br>
[ECCV 2022] [[Project](https://film-net.github.io/)] [[TF2-Code](https://github.com/google-research/frame-interpolation)]<Br>
[â˜…â˜…] end-to-endçš„æ’å¸§ç½‘ç»œ, ä½¿ç”¨ç±»ä¼¼PWCNetçš„å¤šå°ºåº¦flowé¢„æµ‹ç»“æ„, ç‰¹å¾æå–éƒ¨åˆ†ä½¿ç”¨å…±äº«æƒå€¼å¯¹å›¾åƒé‡‘å­—å¡”æç‰¹å¾, é¦–æ¬¡ä½¿ç”¨gram matrix loss, ä½¿ç”Ÿæˆå¸§æ›´æ¸…æ™°. ç½‘ç»œç»“æ„å¾ˆç®€å•æ˜äº†, ä½†æ•ˆæœå¾ˆå¥½, è®­ç»ƒå’Œæ¨¡å‹è®¾è®¡çš„ç»†èŠ‚åº”è¯¥æ˜¯åŠŸä¸å¯æ²¡.

- **Enhancing Deformable Convolution based Video Frame Interpolation with Coarse-to-fine 3D CNN** <Br>
[Duolikun Danier](https://danielism97.github.io/), [Fan Zhang](https://fan-aaron-zhang.github.io/), [David Bull](https://david-bull.github.io/) <Br>
[arXiv 2202] [[Pytorch-Code](https://github.com/danielism97/EDC)]<Br>
[**EDC**]

- **A Subjective Quality Study for Video Frame Interpolation** <Br>
[Duolikun Danier](https://danielism97.github.io/), [Fan Zhang](https://fan-aaron-zhang.github.io/), [David Bull](https://david-bull.github.io/) <Br>
[arXiv 2202] [[Project](https://danielism97.github.io/BVI-VFI/)] <Br>
[**BVI-VFI**]

- **Splatting-based Synthesis for Video Frame Interpolation** <Br>
[Simon Niklaus](http://sniklaus.com/welcome), [Ping Hu](http://cs-people.bu.edu/pinghu/homepage.html), [Jiawen Chen](http://people.csail.mit.edu/jiawen/) <Br>
[arXiv 2201] <Br>

- **Deep Bayesian Video Frame Interpolation** <Br>
Zhiyang Yu, [Yu Zhang](https://zhangyulb.github.io/), Xujie Xiang, Dongqing Zou, Xijun Chen, [Jimmy S. Ren](http://www.jimmyren.com/) <Br>
[ECCV 2022] [[Pytorch-Code](https://github.com/Oceanlib/DBVI)]<Br>
[**DBVI**]

- **IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation** <Br>
Lingtong Kong, [Boyuan Jiang](https://byjiang.com/), Donghao Luo, Wenqing Chu, Xiaoming Huang, [Ying Tai](https://tyshiwo.github.io/), Chengjie Wang, [Jie Yang](http://www.pami.sjtu.edu.cn/jieyang) <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/ltkong218/IFRNet)]<Br

- **ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation** <Br>
[Duolikun Danier](https://danielism97.github.io/), [Fan Zhang](https://fan-aaron-zhang.github.io/), [David Bull](https://david-bull.github.io/) <Br>
[CVPR 2022] [[Project](https://danielism97.github.io/ST-MFNet/)] [[Pytorch-Code](https://github.com/danielism97/st-mfnet)]<Br>
	
- **Real-time Spatial Temporal Transformer** <Br>
[Zhicheng Geng](https://zhichenggeng.com/), Luming Liang, [Tianyu Ding](https://www.tianyuding.com/), Ilya Zharkov <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/llmpass/RSTT)]<Br>
[**RSTT**]

- **Video Frame Interpolation Transformer** <Br>
Zhihao Shi, [Xiangyu Xu](https://sites.google.com/view/xiangyuxu), [Xiaohong Liu](https://jhc.sjtu.edu.cn/~xiaohongliu/), [Jun Chen](https://www.ece.mcmaster.ca/~junchen/), [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/) <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/zhshi0816/Video-Frame-Interpolation-Transformer)]<Br>
	
- **Many-to-many Splatting for Efficient Video Frame Interpolation** <Br>
[Ping Hu](http://cs-people.bu.edu/pinghu/homepage.html), [Simon Niklaus](https://sniklaus.com/welcome), [Stan Sclaroff](https://www.cs.bu.edu/fac/sclaroff/), [Kate Saenko](http://ai.bu.edu/ksaenko.html) <Br>
[CVPR 2022] [[Code](https://github.com/feinanshan/m2m_vfi)]<Br>
[**M2M**] [â˜…â˜…] é¦–å…ˆç”¨off-the-shell modelé¢„æµ‹0->1/1->0çš„å…‰æµ, å†é€šè¿‡motion refinement networké¢„æµ‹Nä¸ªå…‰æµå›¾åŠç½®ä¿¡åº¦map, æœ€ååˆ©ç”¨Nä¸ªå…‰æµè¿›è¡Œforward warpå¹¶fuseç»“æœ. ä½¿ç”¨Low-rank Feature ModulationåŠ å¼ºå…‰æµçš„ä½ç§©çº¦æŸ.

- **DeMFI: Deep Joint Deblurring and Multi-Frame Interpolation with Flow-Guided Attentive Correlation and Recursive Boosting** <Br>
[Jihyong Oh](https://sites.google.com/view/ozbro/%ED%99%88), [Munchurl Kim](https://www.viclab.kaist.ac.kr/) <Br>
[arXiv 2111] [[Pytorch-Code](https://github.com/JihyongOh/DeMFI)]<Br>
	
- **EA-Net: Edge-Aware Network for Flow-based Video Frame Interpolation** <Br>
Bin Zhao, Xuelong Li <Br>
[arXiv 2105] <Br>
[â˜…] åŸºäºå…‰æµçš„æ’å¸§, åŠ å…¥äº†edgeä¿¡æ¯

- **Asymmetric Bilateral Motion Estimation for Video Frame Interpolation** <Br>
Junheum Park, [Chul Lee](http://cilab.dongguk.edu/), [Chang-Su Kim](http://mcl.korea.ac.kr/) <Br>
[ICCV 2021] [[Pytorch-Code](https://github.com/junheum/abme)]<Br>
[**ABME**] [â˜…] å…ˆå¤§è‡´ä¼°è®¡t->0, t->1çš„å…‰æµ, ç”Ÿæˆåˆå§‹It, å†refineå…‰æµå’Œç”Ÿæˆå¸§

- **Revisiting Adaptive Convolutions for Video Frame Interpolation** <Br>
[Simon Niklaus](http://sniklaus.com/welcome), [Long Mai](http://mai-t-long.com/), [Oliver Wang](https://oliverwang.nfshost.com/) <Br>
[WACV 2021] [[Pytorch-Code](https://github.com/sniklaus/revisiting-sepconv)]<Br>
[**SepConv++**] [â˜…] ä½¿ç”¨adaptive convåšæ’å¸§, åœ¨sepconvçš„åŸºç¡€ä¸Šæå‡ºäº†ä¸€äº›trick. è¦ç‚¹ä¸º: 1.é¢„æµ‹xå’Œyæ–¹å‘çš„conv kernel; 2.åœ¨é¢„æµ‹kernelæ—¶ä¸padding; 3.è¾“å…¥ä¸¤å¸§ä¸€èµ·é€channelå½’ä¸€åŒ–åˆ°0å‡å€¼å•ä½æ–¹å·®; 4. å¯¹kernelåšnorm; 5.ä½¿ç”¨VGG loss
	
- **XVFI: eXtreme Video Frame Interpolation** <Br>
Hyeonjun Sim, [Jihyong Oh](https://sites.google.com/view/ozbro/%ED%99%88), Munchurl Kim <Br>
[ICCV 2021 Oral] [[Pytorch-Code](https://github.com/JihyongOh/XVFI)]<Br>
[â˜…â˜…] 1. æå‡ºäº†ä¸€ä¸ª4K, 1000fpsçš„æ’å¸§æ•°æ®é›†; 2. æå‡ºä¸€ä¸ªå…±äº«å‚æ•°çš„å¤šå°ºåº¦æ’å¸§ç½‘ç»œ, é€šè¿‡è°ƒæ•´é¢„æµ‹çš„scaleçº§æ•°, å¤„ç†ä¸åŒåˆ†è¾¨ç‡å’Œåç§».

- **FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation** <Br>
[Tarun Kalluri](https://tarun005.github.io/), [Deepak Pathak](https://www.cs.cmu.edu/~dpathak/), [Manmohan Chandraker](http://cseweb.ucsd.edu/~mkchandraker/), [Du Tran](https://dutran.github.io/)    <Br>
[CVPR 2021] [[Project](https://tarun005.github.io/FLAVR/)] [[Pytorch-Code](https://github.com/tarun005/FLAVR)]<Br>
[â˜…â˜…] é¦–æ¬¡æå‡ºç”¨3Då·ç§¯åšè§†é¢‘æ’å¸§, ç»“æ„ä¸ºUNet, è¾“å…¥ä¸ºå‰åå››å¸§, è¾“å‡ºä¸ºéœ€è¦æ’çš„k-1å¸§

- **CDFI: Compression-Driven Network Design for Frame Interpolation** <Br>
[Tianyu Ding](https://www.tianyuding.com/), Luming Liang, [Zhihui Zhu](http://mysite.du.edu/~zzhu61/index.html), Ilya Zharkov    <Br>
[CVPR 2021] [[Pytorch-Code](https://github.com/tding1/CDFI)]<Br>
[â˜…] é€šè¿‡åŠ å…¥L1æ­£åˆ™å¼•å…¥ç¨€ç–æ€§, ç„¶åå°†æ¨¡å‹è¾“å…¥å±‚æ•°é€æ¬¡å‡å°, å¾—åˆ°å‹ç¼©åçš„æ¨¡å‹. è®ºæ–‡ä¸­è¡¨ç¤ºå‹ç¼©åçš„ç»“æ„æ›´åˆç†, from scratchè®­ç»ƒè¯¥ç½‘ç»œå°±èƒ½å¾—åˆ°ä¸å¤§æ¨¡å‹ç›¸è¿‘çš„æ€§èƒ½. ä¹‹ååœ¨å°æ¨¡å‹ä¸ŠåŠ å…¥äº†ä¸€äº›æ”¹è¿›æ¨¡å—, è¿›ä¸€æ­¥æé«˜äº†ç²¾åº¦

- **Deep Animation Video Interpolation in the Wild** <Br>
Li Siyao, Shiyu Zhao, Weijiang Yu, Wenxiu Sun, [Dimitris N. Metaxas](https://www.cs.rutgers.edu/~dnm/), [Chen Change Loy](http://personal.ie.cuhk.edu.hk/~ccloy/), [Ziwei Liu](https://liuziwei7.github.io/)    <Br>
[CVPR 2021] [[Pytorch-Code](https://github.com/lisiyao21/AnimeInterp/)]<Br>
[**AnimeInterp**] [â˜…] åŠ¨ç”»çš„æ’å¸§, é’ˆå¯¹åŠ¨ç”»çº¹ç†å¹³æ»‘å’Œä½ç§»å¤§çš„ç‰¹ç‚¹, è®¾è®¡äº†segmentåŒ¹é…æ¨¡å—å’Œcoarse-to-fineçš„å…‰æµåŒ¹é…æ¨¡å—.

- **RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation** <Br>
[Zhewei Huang](https://github.com/hzwer), [Tianyuan Zhang](http://tianyuanzhang.com/), Wen Heng, [Boxin Shi](http://ci.idm.pku.edu.cn/), [Shuchang Zhou](https://zsc.github.io/) <Br>
[arXiv 2011] [[Pytorch-Code](https://github.com/hzwer/arXiv2020-RIFE)] [[Software](https://github.com/YiWeiHuang-stack/Squirrel-RIFE)]<Br>
[â˜…â˜…] ä½¿ç”¨ä¸€ä¸ªcoarse-to-fineçš„ç½‘ç»œIFNeté¢„æµ‹f1,f2åˆ°tæ—¶åˆ»çš„å…‰æµ, èåˆéƒ¨åˆ†ä½¿ç”¨ç½‘ç»œé¢„æµ‹fusion mapå’Œresidual. ä¸ºæ›´å¥½è®­ç»ƒå…‰æµ, ä½¿ç”¨leakage distillationçš„æ–¹æ³•, å…ˆç”¨ä¸€è®­ç»ƒå¥½çš„å¤§ç½‘ç»œé¢„æµ‹ä¸­é—´å…‰æµçš„å€¼.

- **Channel Attention Is All You Need for Video Frame Interpolation** <Br>
[Myungsub Choi](https://myungsub.github.io/), Heewon Kim, [Bohyung Han](https://cv.snu.ac.kr/index.php/~bhhan/), Ning Xu, [Kyoung Mu Lee](https://cv.snu.ac.kr/index.php/~kmlee/) <Br>
[AAAI 2020] [[Project](https://myungsub.github.io/CAIN/)] [[Pytorch-Code](https://github.com/myungsub/CAIN)]<Br>
[**CAIN**] [â˜…â˜…] è®¾è®¡äº†ä¸€ä¸ªpixelshuffle + attention residual blockçš„ç½‘ç»œ, æ— éœ€å…‰æµä¼°è®¡å’Œwarpæ“ä½œ.

- **Video Frame Interpolation Via Residue Refinement** <Br>
Haopeng Li, Yuan Yuan, [Qi Wang](http://crabwq.github.io/#top) <Br>
[ICASSP  2020] [[Pytorch-Code](https://github.com/HopLee6/RRIN)]<Br>
[**RRIN**] [â˜…] æ®‹å·®å’ŒUNetç»“æ„é¢„æµ‹å…‰æµ, warp, refine

- **BMBC: Bilateral Motion Estimation with Bilateral Cost Volume for Video Interpolation** <Br>
Junheum Park, Keunsoo Ko, [Chul Lee](http://cilab.dongguk.edu/), [Chang-Su Kim](http://mcl.korea.ac.kr/) <Br>
[ECCV 2020] [[Pytorch-Code](https://github.com/JunHeum/BMBC)]<Br>
[**BMBC**] [â˜…] åŸºäºå…‰æµçš„æ’å¸§, æå‡ºäº†ç”¨ä¸­é—´å…‰æµå€¼å–å¾—å‰åå¸§çš„featureç»„æˆbilateral cost volume

- **All at Once: Temporally Adaptive Multi-Frame Interpolation with Advanced Motion Modeling** <Br>
Zhixiang Chi, Rasoul Mohammadi Nasiri, Zheng Liu, [Juwei Lu](https://www.dsp.utoronto.ca/juwei/), Jin Tang, [Konstantinos N Plataniotis](https://www.comm.utoronto.ca/~kostas/) <Br>
[ECCV 2020] [[Project](https://chi-chi-zx.github.io/all-at-once/)] [[Code](https://github.com/chi-chi-zx/all-at-once)]<Br>
[â˜…] 1.ä½¿ç”¨ä¸‰æ¬¡å¤šé¡¹å¼å¯¹å…‰æµå»ºæ¨¡; 2.ç”¨temporal pyramidalå½¢å¼, æœ‰æ˜“åˆ°éš¾é€æ¬¡ä¼°è®¡t1/t7->t2/t6->t3/t5->t4; 3. ä¼°è®¡å…‰æµæ—¶, ä½¿ç”¨relaxed loss, å³å…è®¸ä¼°è®¡çš„å…‰æµæœ‰å°èŒƒå›´è¯¯å·®

- **Enhanced Quadratic Video Interpolation** <Br>
Yihao Liu, Liangbin Xie, Li Siyao, Wenxiu Sun, Yu Qiao, Chao Dong <Br>
[ECCVW 2020] [[Pytorch-Code](https://github.com/lyh-18/EQVI)]<Br>
[**EQVI**] [â˜…] 1.ç”¨æœ€å°äºŒä¹˜è®¡ç®—quadraticå…‰æµ; 2.ç”¨resnet18æå–çš„contextualç‰¹å¾å’ŒåŸå›¾ä¸€èµ·é¢„æµ‹æ®‹å·®; 3.å¯¹ä¸¤ä¸ªå°ºåº¦çš„è¾“å…¥ç”¨ç›¸åŒç½‘ç»œå¤„ç†, å¹¶ç”¨ä¸€ä¸ªfusion neté¢„æµ‹mapè¿›è¡Œèåˆ

- **Video Frame Interpolation without Temporal Priors** <Br>
 Youjian Zhang, [Chaoyue Wang](https://wang-chaoyue.github.io/), [Dacheng Tao](https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html) <Br>
[NeurIPS 2020] [[Pytorch-Code](https://github.com/yjzhang96/UTI-VFI)]<Br>
[**UTI-VFI**] [â˜…] ç”¨æ®‹å·®ç½‘ç»œå…ˆä»æ¨¡ç³Šå¸§ä¸­é¢„æµ‹æ¸…æ™°çš„èµ·å§‹å’Œç»“æŸå…³é”®å¸§, å†ç”¨äºŒæ¬¡å…‰æµrefine

- **Softmax Splatting for Video Frame Interpolation** <Br>
 [Simon Niklaus](http://sniklaus.com/welcome), [Feng Liu](http://web.cecs.pdx.edu/~fliu/) <Br>
[CVPR 2020] [[Pytorch-Code](https://github.com/sniklaus/softmax-splatting)]<Br>
[**SoftSplat**] [â˜…â˜†] ä½¿ç”¨å‰å‘å…‰æµwarpçš„æ’å¸§, å¤§è‡´æµè§ˆ, æ•ˆæœä¸é”™. ä¸»è¦åˆ›æ–°ç‚¹ä¸ºä½¿ç”¨I0å’ŒI1_warpçš„äº®åº¦ä¸€è‡´æ€§ä½œä¸ºæƒé‡Z, å¹¶ç”¨ä¸€ç½‘ç»œrefine Z, æœ€ååœ¨èåˆæ—¶ä½¿ç”¨expä¿è¯äº†å°ºåº¦ä¸å˜æ€§(æ­¤å¤„æ˜¯ä»æ·±åº¦å›¾ä½œä¸ºZæ¥è®ºè¿°çš„).

- **Scene-Adaptive Video Frame Interpolation via Meta-Learning** <Br>
 [Myungsub Choi](https://myungsub.github.io/), Janghoon Choi, [Sungyong Baik](https://baiksung.github.io/), [Tae Hyun Kim](https://sites.google.com/site/lliger9/), [Kyoung Mu Lee](https://cv.snu.ac.kr/index.php/~kmlee/) <Br>
[CVPR 2020] [[Project](https://myungsub.github.io/meta-interpolation/)] [[Pytorch-Code](https://github.com/myungsub/meta-interpolation)]<Br>
[**Meta Interpolation**]

- **FeatureFlow: Robust Video Interpolation via Structure-to-Texture Generation** <Br>
Shurui Gui, [Chaoyue Wang](https://wang-chaoyue.github.io/), Qihua Chen, [Dacheng Tao](https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html) <Br>
[CVPR 2020] [[Pytorch-Code](https://github.com/CM-BF/FeatureFlow)]<Br>
[â˜…] é¦–å…ˆ, æ ¹æ®ä¸¤å¸§è¾“å…¥å›¾åƒå’Œedge, é¢„æµ‹ä¸­é—´å¸§çš„structureå›¾; ç„¶åè®¾è®¡äº†ä¸€ä¸ªtexture compensatorç”Ÿæˆçº¹ç†ç»†èŠ‚. ç½‘ç»œç”¨deformable convåšæ’å¸§å’Œçº¹ç†è¡¥å¿.

- **Blurry Video Frame Interpolation** <Br>
[Wang Shen](https://sites.google.com/view/wangshen94), [Wenbo Bao](https://sites.google.com/view/wenbobao/home), [Guangtao Zhai](https://faculty.sjtu.edu.cn/zhaiguangtao/en/index.htm), Li Chen, [Xiongkuo Min](https://sites.google.com/site/minxiongkuo/home), Zhiyong Gao<Br>
[CVPR 2020 Oral] [[Pytorch-Code](https://github.com/laomao0/BIN)]<Br>
[**BIN**] [â˜…] ç©ºé—´é‡‡ç”¨é‡‘å­—å¡”å‹ç»“æ„, é€å±‚åˆ©ç”¨å¤šå¸§ä¿¡æ¯, ä¸ºä¿è¯å¸§é—´ä¸€è‡´æ€§, ä½¿ç”¨äº†ConvLSTMæŒ–æ˜temporalå…³ç³»

- **AdaCoF: Adaptive Collaboration of Flows for Video Frame Interpolation** <Br>
[Hyeongmin Lee](https://hyeongminlee.github.io/), [Taeoh Kim](https://taeoh-kim.github.io/), Tae-young Chung, Daehyun Pak, Yuseok Ban, Sangyoun Lee <Br>
[CVPR 2020] [[Pytorch-Code](https://github.com/HyeongminLEE/AdaCoF-pytorch)]<Br>
	
- **Deep Slow Motion Video Reconstruction with Hybrid Imaging System** <Br>
[Avinash Paliwal](http://people.tamu.edu/~avinashpaliwal/), [Nima Kalantari](https://people.engr.tamu.edu/nimak/index.html) <Br>
[TPAMI 2020] [[Project](https://people.engr.tamu.edu/nimak/Papers/ICCP2020_Slomo/index.html)] [[Pytorch-Code](https://github.com/avinashpaliwal/Deep-SloMo)]<Br>
[**Deep-SloMo**]

- **Robust Video Frame Interpolation With Exceptional Motion Map** <Br>
 Minho Park, [Hak Gu Kim](https://haku0331.wixsite.com/hakgukim), [Sangmin Lee](https://sites.google.com/view/sangmin-lee), [Yong Man Ro](http://ivylab.kaist.ac.kr/default/) <Br>
[TCSVT 2020] <Br>
	
- **ALANET: Adaptive Latent Attention Network for Joint Video Deblurring and Interpolation** <Br>
[Akash Gupta](https://akashagupta.com/), [Abhishek Aich](https://abhishekaich27.github.io/), [Amit K. Roy-Chowdhury](https://vcg.engr.ucr.edu/amit) <Br>
[MM 2020] [[Project](https://akashagupta.com/ALANET.html)] [[Code](https://github.com/agupt013/ALANET)]<Br>
[â˜…] ç”¨å¸§å†…å’Œå¸§é—´attentionåšå»æ¨¡ç³Šå’Œæ’å¸§
	
- **Depth-Aware Video Frame Interpolation** <Br>
[Wenbo Bao](https://sites.google.com/view/wenbobao/home), [Wei-Sheng Lai](http://graduatestudents.ucmerced.edu/wlai24/), [Chao Ma](https://vision.sjtu.edu.cn/), Xiaoyun Zhang, Zhiyong Gao, [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/)  <Br>
[CVPR 2019] [[Project](https://sites.google.com/view/wenbobao/dain)] [[Pytorch-Code](https://github.com/baowenbo/DAIN)]<Br>
[**DAIN**] [â˜…â˜…â˜†]

- **Unsupervised Video Interpolation using Cycle Consistency** <Br>
Fitsum A. Reda, Deqing Sun, Aysegul Dundar, Mohammad Shoeybi, [Guilin Liu](https://liuguilin1225.github.io/), Kevin J. Shih, Andrew Tao, [Jan Kautz](http://jankautz.com/), [Bryan Catanzaro](http://catanzaro.name/)  <Br>
[ICCV 2019] [[Project](https://nv-adlr.github.io/publication/2019-UnsupervisedVideoInterpolation)] [[Pytorch-Code](https://github.com/NVIDIA/unsupervised-video-interpolation)]<Br>

- **IM-Net for High Resolution Video Frame Interpolationn** <Br>
Tomer Peleg, Pablo Szekely, Doron Sabo, [Omry Sendik](https://omrysendik.github.io/)  <Br>
[CVPR 2019] [[Project](https://sites.google.com/view/wenbobao/dain)] [[Pytorch-Code](https://github.com/baowenbo/DAIN)]<Br>
[â˜…] é¢„æµ‹motion field vector(å…‰æµ)å’Œocclusion mapåšæ’å¸§

- **Quadratic video interpolation** <Br>
[Xiangyu Xu](https://sites.google.com/view/xiangyuxu), Siyao Li, Wenxiu Sun, Qian Yin, [Ming-Hsuan Yang](https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=zh-CN&oi=sra)   <Br>
[NeurIPS 2019] [[Project](https://sites.google.com/view/xiangyuxu/qvi_nips19)] [[Pytorch-Code](https://github.com/xuxy09/QVI)]<Br>
[**QVI**] [â˜…] åˆ©ç”¨-1,0,1ä¸‰å¸§çš„ä¿¡æ¯å¯¹å…‰æµè¿›è¡ŒäºŒæ¬¡æ’å€¼

- **Deep Video Frame Interpolation using Cyclic Frame Generation** <Br>
[Yu-Lun Liu](http://www.cmlab.csie.ntu.edu.tw/~yulunliu/), [Yi-Tung Liao](http://www.cmlab.csie.ntu.edu.tw/~queenieliaw/), [Yen-Yu Lin](https://www.citi.sinica.edu.tw/pages/yylin/), [Yung-Yu Chuang](https://www.csie.ntu.edu.tw/~cyy/)   <Br>
[[Project](https://www.cmlab.csie.ntu.edu.tw/~yulunliu/CyclicGen)] [[TF-Code](https://github.com/alex04072000/CyclicGen)]<Br>
[**CyclicGen**] [â˜…â˜†] ç”¨2ä¸ªé¢„æµ‹å¸§é¢„æµ‹è¾“å…¥å¸§, ä½œä¸ºconsistency loss, æé«˜ç”Ÿæˆå¸§çš„è´¨é‡. å¦å¤–æå‡ºäº†å…‰æµçº¿æ€§çº¦æŸloss, å¹¶å°†è¾¹ç¼˜ä¿¡æ¯åŠ å…¥åˆ°è¾“å…¥ä¸­

- **MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement** <Br>
[Wenbo Bao](https://sites.google.com/view/wenbobao/home), [Wei-Sheng Lai](http://graduatestudents.ucmerced.edu/wlai24/), Xiaoyun Zhang, Zhiyong Gao, [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/)    <Br>
[TPAMI 2019] [[Project](https://sites.google.com/view/wenbobao/memc-net)] [[Pytorch-Code](https://github.com/baowenbo/MEMC-Net)]<Br>
[â˜…â˜…] æå‡ºä¸€ä¸ªè‡ªé€‚åº”warping layer, å°†warpingä¸­ç®€å•çš„bilinearæ“ä½œæ”¹ä¸ºå­¦ä¹ çš„æ’å€¼kernelä¸åŒçº¿æ€§æ ¸ç›¸ç»“åˆçš„æ“ä½œ

- **Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation** <Br>
[Huaizu Jiang](http://jianghz.me/), [Deqing Sun](https://deqings.github.io/), [Varun Jampani](https://varunjampani.github.io/), [Ming-Hsuan Yang](https://faculty.ucmerced.edu/mhyang/), [Erik Learned-Miller](https://people.cs.umass.edu/~elm/), [Jan Kautz](https://jankautz.com/)  <Br>
[CVPR 2018] [[Project](https://github.com/avinashpaliwal/Super-SloMo)] [[Pytorch-Code](http://jianghz.me/projects/superslomo/)]<Br>
[â˜…â˜†] è§†é¢‘æ’å¸§. é¦–å…ˆé¢„æµ‹åŒå‘å…‰æµ, æ¥ä¸‹æ¥åœ¨æ¯ä¸ªè¦æ’å€¼çš„æ—¶åˆ»t, ç”¨ä¸€ä¸ªç½‘ç»œrefineå…‰æµå¹¶é¢„æµ‹visibility map, æœ€åæ ¹æ®å…‰æµå’Œvisibility mapæ’å€¼ç”Ÿæˆtæ—¶åˆ»å›¾åƒ.

- **Context-aware Synthesis for Video Frame Interpolation** <Br>
[Simon Niklaus](http://sniklaus.com/welcome), [Feng Liu](http://web.cecs.pdx.edu/~fliu/) <Br>
[CVPR 2018] [[Project](http://web.cecs.pdx.edu/~fliu/project/adaconv/)] <Br>
	
- **Video Frame Interpolation via Adaptive Separable Convolution** <Br>
[Simon Niklaus](http://sniklaus.com/welcome), Long Mai, [Feng Liu](http://web.cecs.pdx.edu/~fliu/) <Br>
[ICCV 2017] [[Project](http://web.cecs.pdx.edu/~fliu/project/sepconv/)] [[Pytorch-Code](https://github.com/sniklaus/sepconv-slomo)]<Br>
[**sepconv-slomo**]

- **Video Frame Interpolation via Adaptive Convolution** <Br>
[Simon Niklaus](http://sniklaus.com/welcome), Long Mai, [Feng Liu](http://web.cecs.pdx.edu/~fliu/) <Br>
[CVPR 2017] [[Project](http://web.cecs.pdx.edu/~fliu/project/adaconv/)] <Br>
[**adaconv-slomo**]
	
	
	
	
# Video Enhancement and Restoration
- **Snow Removal in Video: A New Dataset and A Novel Method** <Br>
[Haoyu Chen](https://haoyuchen.com/), Jingjing Ren, [Jinjin Gu](https://www.jasongt.com/), Hongtao Wu, Xuequan Lu, [Haoming Cai](https://www.haomingcai.com/), [Lei Zhu](https://sites.google.com/site/indexlzhu/home?authuser=0)  <Br>
[ICCV 2023] [[Project](https://haoyuchen.com/VideoDesnowing)] [[Pytorhc-Code](https://github.com/haoyuc/VideoDesnowing)] <Br>

- **Recurrent Video Restoration Transformer with Guided Deformable Attention** <Br>
[Jingyun Liang](https://jingyunliang.github.io/), [Yuchen Fan](https://ychfan.github.io/), [Xiaoyu Xiang](https://engineering.purdue.edu/people/xiaoyu.xiang.1), Rakesh Ranjan, [Eddy Ilg](https://cvmp.cs.uni-saarland.de/), Simon Green, [Jiezhang Cao](https://www.jiezhangcao.com/), [Kai Zhang](https://cszn.github.io/), [Radu Timofte](http://people.ee.ethz.ch/~timofter/), [Luc Van Gool](https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html)  <Br>
[NeurlPS 2022] [[Pytorhc-Code](https://github.com/JingyunLiang/RVRT)] <Br>
[**RVRT**]

- **Context-Aware Video Reconstruction for Rolling Shutter Cameras** <Br>
[Bin Fan](https://gitcvfb.github.io/), [Yuchao Dai](http://npu-cvr.cn/), Zhiyuan Zhang, Qi Liu, Mingyi He <Br>
[CVPR 2022] [[Code](https://github.com/GitCVfb/CVR)] <Br>
[**CVR**]

- **Neural Global Shutter: Learn to Restore Video from a Rolling Shutter Camera with Global Reset Feature** <Br>
[Zhixiang Wang](https://lightchaserx.github.io/), Xiang Ji, Jia-Bin Huang, [Shin'ichi Satoh](http://www.satoh-lab.nii.ac.jp/), Xiao Zhou, Yinqiang Zheng <Br>
[CVPR 2022] [[Code](https://github.com/lightChaserX/neural-global-shutter)] <Br>

- **Bringing Old Films Back to Life** <Br>
[Ziyu Wan](http://raywzy.com/), [Bo Zhang](https://bo-zhang.me/), [Dongdong Chen](http://www.dongdongchen.bid/), [Jing Liao](https://liaojing.github.io/html/) <Br>
[CVPR 2022] [[Project](http://raywzy.com/Old_Film/)] <Br>

- **Revisiting Temporal Alignment for Video Restoration** <Br>
Kun Zhou, [Wenbo Li](https://fenglinglwb.github.io/), Liying Lu, Xiaoguang Han, [Jiangbo Lu](https://sites.google.com/site/jiangbolu/) <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/redrock303/Revisiting-Temporal-Alignment-for-Video-Restoration)] <Br>

- **VRT: A Video Restoration Transformer** <Br>
[Jingyun Liang](https://jingyunliang.github.io/), [Jiezhang Cao](https://www.jiezhangcao.com/), [Yuchen Fan](https://ychfan.github.io/), [Kai Zhang](https://cszn.github.io/), Rakesh Ranjan, [Yawei Li](https://ofsoundof.github.io/), [Radu Timofte](http://people.ee.ethz.ch/~timofter/), [Luc Van Gool](https://ee.ethz.ch/the-department/faculty/professors/person-detail.OTAyMzM=.TGlzdC80MTEsMTA1ODA0MjU5.html) <Br>
[arXiv 2201] [[Pytorch-Code](https://github.com/JingyunLiang/VRT)] <Br>
ğŸ”¥
	
- **Learning Temporal Consistency for Low Light Video Enhancement from Single Images** <Br>
Fan Zhang, [Yu Li](https://yu-li.github.io/), [Shaodi You](https://youshaodi.github.io/), Ying Fu <Br>
[CVPR 2021] [[Pytorch-Code](https://github.com/zkawfanx/StableLLVE)]**
[â˜…â˜†] è®­ç»ƒæ—¶, å¯¹å›¾åƒåšåˆ†å‰²å¹¶é¢„æµ‹å‰æ™¯çš„éšæœºå…‰æµ, è®¡ç®—warpåå›¾åƒå’ŒåŸå›¾åƒå¤„ç†ç»“æœçš„consistency loss, åŠ å¼ºæ—¶é—´ä¸€è‡´æ€§, å¦å¤–åœ¨ç”Ÿæˆè®­ç»ƒæ ·æœ¬æ—¶, åŠ å…¥äº†ä¸€äº›noise.

- **EDVR: Video Restoration with Enhanced Deformable Convolutional Networks** <Br>
 [Xintao Wang](https://xinntao.github.io/), [Kelvin C.K. Chan](https://ckkelvinchan.github.io/), [Ke Yu](https://yuke93.github.io/), Chao Dong, [Chen Change Loy](https://www.mmlab-ntu.com/person/ccloy/) <Br>
[CVPRW 2019] [[Project](https://xinntao.github.io/projects/EDVR)] [[Pytorch-Code](https://github.com/xinntao/EDVR)] <Br>

- **Learning to See Moving Objects in the Dark** <Br>
 Haiyang Jiang, Yinqiang Zheng <Br>
[ICCV 2019] [[TF-Code](https://github.com/MichaelHYJiang/Learning-to-See-Moving-Objects-in-the-Dark)] <Br>
[â˜…â˜…] æä¾›äº†ä¸€ä¸ªæš—å…‰è§†é¢‘å¢å¼ºæ•°æ®é›†, é€šè¿‡è®¾è®¡camera system, è·å–å¯¹é½çš„äº®æš—è§†é¢‘å¯¹. è®¾è®¡ä¸€ä¸ªåŸºäº3DUnetçš„ç½‘ç»œ.

- **Seeing Motion in the Dark** <Br>
[Chen Chen](http://cchen156.web.engr.illinois.edu/), [Qifeng Chen](http://cqf.io/), [Minh N. Do](http://minhdo.ece.illinois.edu/), [Vladlen Koltun](http://vladlen.info/) <Br>
[ICCV 2019] [[TF-Code](https://github.com/cchen156/Seeing-Motion-in-the-Dark)] <Br>
[â˜…â˜†] å¯¹ä¸€ç»„é™æ€çš„è§†é¢‘å¸§åšäº®åº¦å¢å¼º, ä½¿ç”¨Deep Siamese Network, å¢å¼ºå¸§é—´ä¸€è‡´æ€§.
	



# Video Stabilization
- **Deep Online Fused Video Stabilization** <Br>
 [Zhenmei Shi](http://pages.cs.wisc.edu/~zhmeishi/), [Fuhao Shi](http://fuhaoshi.com/), [Wei-Sheng Lai](http://graduatestudents.ucmerced.edu/wlai24/), [Chia-Kai Liang](http://chiakailiang.org/), [Yingyu Liang](http://pages.cs.wisc.edu/~yliang/) <Br>
[arXiv 2102] [[Project](https://zhmeishi.github.io/dvs/)] [[Pytorch-Code](https://github.com/googleinterns/deep-stabilization)] <Br>










# Video Debluring
- **Deep Discriminative Spatial and Temporal Network for Efficient Video Deblurring** <Br>
[Jinshan Pan](https://jspan.github.io/)], Boming Xu, Jiangxin Dong, Jianjun Ge, [Jinhui Tang](https://imag-njust.net/) <Br>
[CVPR 2023] [[Pytorch-Code](https://github.com/xuboming8/DSTNet)]<Br>
[**DSTNet**]

- **Multi-Scale Memory-Based Video Deblurring** <Br>
Bo Ji, [Angela Yao](https://www.comp.nus.edu.sg/~ayao/) <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/jibo27/MemDeblur)]<Br>

- **DeFMO: Deblurring and Shape Recovery of Fast Moving Objects** <Br>
Denys Rozumnyi, Martin R. Oswald, Vittorio Ferrari, Jiri Matas, Marc Pollefeys<Br>
[CVPR 2021] [[Pytorch-Code](https://github.com/rozumden/DeFMO)]<Br>
[â˜…] ä»å•å¼ æ¨¡ç³Šå›¾åƒå’ŒèƒŒæ™¯å›¾ä¸­æ¢å¤tå¼ æ¸…æ™°çš„å›¾åƒ, ç½‘ç»œç»“æ„ä¸ºä¸€ä¸ªencoder+tä¸ªrenderers, é‡‡ç”¨äº†å‡ ä¸ªlossåˆ†åˆ«ç”¨äºå¤„ç†ç›®æ ‡å¤–è§‚, sharpnessåŠç©ºé—´ä¸€è‡´æ€§ç­‰.
	
- **ARVo: Learning All-Range Volumetric Correspondence for Video Deblurring** <Br>
Dongxu Li, Chenchen Xu, [Kaihao Zhang](https://zhangkaihao.github.io/), [Xin Yu](https://sites.google.com/view/xinyus-homepage/Home), [Yiran Zhong](https://yiranzhong.com/), [Wenqi Ren](https://sites.google.com/site/renwenqi888/home), [Hanna Suominen](https://researchers.anu.edu.au/researchers/suominen-h), Hongdong Li<Br>
[CVPR 2021] [[Project](https://baihaoran.xyz/projects/cdvd-tsp/index.html)] [[Pytorch-Code](https://github.com/csbhr/CDVD-TSP)]<Br>

- **Learning Event-Driven Video Deblurring and Interpolation** <Br>
Songnan Lin, [Jiawei Zhang](https://sites.google.com/site/zhjw1988), [Jinshan Pan](https://jspan.github.io/), Zhe Jiang, Dongqing Zou, Yongtian Wang, Jing Chen, [Jimmy Ren](http://www.jimmyren.com/) <Br>
[ECCV 2020] <Br>

- **Efficient Spatio-Temporal Recurrent Neural Network for Video Deblurring** <Br>
Zhihang Zhong, Ye Gao, Yinqiang Zheng, [Bo Zheng](http://www.bozheng-lab.com/) <Br>
[ECCV 2020 Spotlight] [[Pytorch-Code](https://github.com/zzh-tech/ESTRNN)]<Br>
[**ESTRNN**]

- **Cascaded Deep Video Deblurring Using Temporal Sharpness Prior** <Br>
[Jinshan Pan](https://jspan.github.io/), [Haoran Bai](https://baihaoran.xyz/about), Jinhui Tang<Br>
[CVPR 2020] [[Project](https://baihaoran.xyz/projects/cdvd-tsp/index.html)] [[Pytorch-Code](https://github.com/csbhr/CDVD-TSP)]<Br>
[**CDVD-TSP**] [â˜…â˜†] ä½¿ç”¨å…‰æµå°†å…ˆåå¸§warpåˆ°å½“å‰å¸§, å’Œä¸€ä¸ªæ–°æå‡ºçš„sharpness priorè¿›è¡Œconcat, é€å…¥ç½‘ç»œè¿›è¡Œå¤„ç†. é€šè¿‡çº§è”(2é˜¶æ®µ)çš„æ–¹å¼æé«˜ç²¾åº¦.

- **Spatio-Temporal Filter Adaptive Network for Video Deblurring** <Br>
[Shangchen Zhou](https://shangchenzhou.com/), [Jiawei Zhang](https://sites.google.com/site/zhjw1988), [Jinshan Pan](https://jspan.github.io/), [Haozhe Xie](https://haozhexie.com/about), [Wangmeng Zuo](http://homepage.hit.edu.cn/wangmengzuo), [Jimmy Ren](http://www.jimmyren.com/) <Br>
[ICCV 2019] [[Project](https://www.shangchenzhou.com/projects/stfan/)] [[Pytorch-Code](https://github.com/sczhou/STFAN)]<Br>
[**STFAN**]


# Video Deraining
- **Semi-supervised Video Deraining with Dynamical Rain Generator**  <Br>
Zongsheng Yue, [Jianwen Xie](http://www.stat.ucla.edu/~jxie/), Qian Zhao, [Deyu Meng](http://gr.xjtu.edu.cn/web/dymeng/1) <Br>	
[CVPR 2021] [[Pytorch-Code](https://github.com/zsyOAOA/S2VD)]<Br>
[**S2VD**]


# Video Dehazing
- **Learning to Restore Hazy Video: A New Real-World Dataset and A New Method** <Br>
[Xinyi Zhang](https://sites.cs.ucsb.edu/~xyzhang/), Hang Dong, [Jinshan Pan](https://jspan.github.io/), Chao Zhu, [Ying Tai](https://tyshiwo.github.io/), Chengjie Wang, Jilin Li, Feiyue Huang, Fei Wang <Br>
[CVPR 2021] <Br>


# Video Deflicker
- **Blind Video Deflickering by Neural Filtering with a Flawed Atlas** <Br>
[Chenyang Lei](https://chenyanglei.github.io/), [Xuanchi Ren](https://xuanchiren.com/), [Zhaoxiang Zhang](https://zhaoxiangzhang.net/), [Qifeng Chen](https://cqf.io/) <Br>
[CVPR 2023] [[Project](https://chenyanglei.github.io/deflicker/)] [[Pytorch-Code](https://github.com/ChenyangLEI/All-in-one-Deflicker)]<Br>


# Video Inpainting
- **ProPainter: Improving Propagation and Transformer for Video Inpainting** <Br>
[Shangchen Zhou](https://shangchenzhou.com/),â€ƒ [Chongyi Li](https://li-chongyi.github.io/),â€ƒ [Kelvin C.K. Chan](https://ckkelvinchan.github.io/),,â€ƒ [Chen Change Loy](http://personal.ie.cuhk.edu.hk/~ccloy/) <Br>
[ICCV 2023] [[Project](https://chenyanglei.github.io/deflicker/)] [[Pytorch-Code](https://github.com/sczhou/ProPainter)]
ğŸ”¥

- **The DEVIL is in the Details: A Diagnostic Evaluation Benchmark for Video Inpainting** <Br>
[Ryan Szeto](http://ryanszeto.com/), [Jason J. Corso](http://web.eecs.umich.edu/~jjcorso/) <Br>
[CVPR 2022] [[Code](https://github.com/MichiganCOG/devil)]

- **Towards An End-to-End Framework for Flow-Guided Video Inpainting** <Br>
[Zhen Li](https://paper99.github.io/), Cheng-Ze Lu, Jianhua Qin, Chun-Le Guo, [Ming-Ming Cheng](http://mmcheng.net/cmm/) <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/MCG-NKU/E2FGVI)]
[**E2FGVI**]

- **Internal Video Inpainting by Implicit Long-range Propagation** <Br>
[Hao Ouyang](https://ken-ouyang.github.io/), [Tengfei Wang](https://tengfei-wang.github.io/), [Qifeng Chen](https://cqf.io/publication.html) <Br>
[ICCV 2021] [[Project](https://tengfei-wang.github.io/Implicit-Internal-Video-Inpainting/index.html)] [[Pytorch-Code](https://github.com/Tengfei-Wang/Implicit-Internal-Video-Inpainting)]
[**IIVI**]

- **Progressive Temporal Feature Alignment Network for Video Inpainting** <Br>
Xueyan Zou, [Linjie Yang](https://sites.google.com/site/linjieyang89/), Ding Liu, [Yong Jae Lee](https://web.cs.ucdavis.edu/~yjlee/) <Br>
[CVPR 2021] [[Pytorch-Code](https://github.com/MaureenZOU/TSAM)]
[**TSAM**]

- **Short-Term and Long-Term Context Aggregation Network for Video Inpainting** <Br>
[Ang Li](https://angliunimelb.github.io/), [Shanshan Zhao](https://sshan-zhao.github.io/), [Xingjun Ma](http://xingjunma.com/), [Mingming Gong](https://mingming-gong.github.io/), [Jianzhong Qi](https://people.eng.unimelb.edu.au/jianzhongq/), [Rui Zhang](http://www.ruizhang.info/), [Dacheng Tao](https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html), [Ramamohanarao Kotagirig](http://www.cloudbus.org/rao/) <Br>
[ECCV 2020] <Br>

- **Learning Joint Spatial-Temporal Transformations for Video Inpainting**  <Br>
[Yanhong Zeng](https://sites.google.com/view/1900zyh), [Jianlong Fu](https://jianlong-fu.github.io/), Hongyang Chao <Br>
[ECCV 2020] [[Pytorch-Code](https://github.com/researchmm/STTN)]
[**STTN**]

- **DVI: Depth Guided Video Inpainting for Autonomous Driving** <Br>
Miao Liao, Feixiang Lu, Dingfu Zhou, [Sibo Zhang](https://sites.google.com/view/sibozhang/home), Wei Li, [Ruigang Yang](http://www.vis.uky.edu/~ryang/) <Br>
[ECCV 2020] [[Project](https://sites.google.com/view/sibozhang/dvi)] [[Code](https://github.com/sibozhang/Depth-Guided-Inpainting)]


	
# Video Matting
- **VMFormer: End-to-End Video Matting with Transformer** <Br>
[Jiachen Li](https://chrisjuniorli.github.io/), [Vidit Goel](https://vidit98.github.io/), Marianna Ohanyan, Shant Navasardyan, [Yunchao Wei](https://weiyc.github.io/), [Humphrey Shi](https://www.humphreyshi.com/) <Br>
[arXiv 2205] [[Project](https://chrisjuniorli.github.io/project/VMFormer/)] [[Pytorch-Code](https://github.com/SHI-Labs/VMFormer)]<Br>

- **One-Trimap Video Matting** <Br>
[Hongje Seong](https://hongje.github.io/), [Seoung Wug Oh](https://sites.google.com/view/seoungwugoh), [Brian Price](https://www.brianpricephd.com/), [Euntai Kim](https://cilab.yonsei.ac.kr/), [Joon-Young Lee](https://joonyoung-cv.github.io/) <Br>
[ECCV 2022] [[Pytorch-Code](https://github.com/Hongje/OTVM)] <Br>
[**OTVM**]

- **Human Instance Matting via Mutual Guidance and Multi-Instance Refinement** <Br>
Yanan Sun, Chi-Keung Tang, Yu-Wing Tai <Br>
[CVPR 2022 Oral] [[Pytorch-Code](https://github.com/nowsyn/InstMatt)] <Br>
[**InstMatt**]

- **MatteFormer: Transformer-Based Image Matting via Prior-Tokens** <Br>
GyuTae Park, SungJoon Son, JaeYoung Yoo, SeHo Kim, [Nojun Kwak](http://mipal.snu.ac.kr/) <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/webtoon/matteformer)] <Br>

- **Robust High-Resolution Video Matting with Temporal Guidance** <Br>
Shanchuan Lin, Linjie Yang, Imran Saleemi, [Soumyadip Sengupta](https://homes.cs.washington.edu/~soumya91/) <Br>
[WACV 2022] [[Project](https://peterl1n.github.io/RobustVideoMatting/#/)] [[Pytorch-Code](https://github.com/PeterL1n/RobustVideoMatting)] <Br>
è½»é‡çº§è§†é¢‘matting, æ•ˆæœä¸é”™. ç”¨ConvGRUåˆ©ç”¨æ—¶åŸŸä¿¡æ¯, ç”¨Deep guided filterå¤„ç†å¤§å›¾  <Br>
[**RVM**] [â˜…â˜…]

- **Deep Video Matting via Spatio-Temporal Alignment and Aggregation** <Br>
[Yanan Sun](https://georgegu1997.github.io/), [Guanzhi Wang](https://cs.stanford.edu/~guanzhi/), Qiao Gu, [Chi-Keung Tang](http://www.cse.ust.hk/~cktang/), [Yu-Wing Tai](https://www.cse.ust.hk/admin/people/faculty/profile/yuwing) <Br>
[CVPR 2021] <Br>
[**DVM**]
	

# Video Demoireing
- **Video Demoireing with Relation-Based Temporal Consistency** <Br>
Peng Dai, Xin Yu, Lan Ma, Baoheng Zhang, Jia Li, [Wenbo Li](https://fenglinglwb.github.io/), Jiajun Shen, [Xiaojuan Qi](https://xjqi.github.io/) <Br>
[CVPR 2022] [[Project](https://daipengwa.github.io/VDmoire_ProjectPage/)] [[Pytorch-Code](https://github.com/CVMI-Lab/VideoDemoireing)] <Br>



# Video Synthesis
- **Pyramidal Flow Matching for Efficient Video Generative Modeling** <Br>
[Yang Jin](https://jy0205.github.io/), [Zhicheng Sun](https://feifeiobama.github.io/), Ningyuan Li, [Kun Xu](https://sites.google.com/view/kunxu/home), Kun Xu, Hao Jiang, Nan Zhuang, [Quzhe Huang](https://andrewzhe.github.io/), Yang Song, Yadong Mu, [Zhouchen Lin](https://zhouchenlin.github.io/) <Br>
[arXiv 2410] [[Project](pyramid-flow.github.io/)] [[Pytorch-Code](https://github.com/jy0205/Pyramid-Flow)]   <Br>
[**Pyramidal Flow**] ğŸ”¥  <Br>
![](https://img.shields.io/github/stars/jy0205/Pyramid-Flow)


- **CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer** <Br>
Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, Da Yin, Xiaotao Gu, Yuxuan Zhang, Weihan Wang, Yean Cheng, Ting Liu, Bin Xu, Yuxiao Dong, Jie Tang <Br>
[CVPR 2024] [[Pytorch-Code](https://github.com/THUDM/CogVideo)]  <Br>
[**CogVideo**] ğŸ”¥ <Br>
![](https://img.shields.io/github/stars/THUDM/CogVideo)

- **MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation** <Br>
Ludan Ruan, [Yiyang Ma](https://realpasu.github.io/), [Huan Yang](https://hyang0511.github.io/), Huiguo He, Bei Liu, [Jianlong Fu](https://www.microsoft.com/en-us/research/people/jianf/), Nicholas Jing Yuan, Qin Jin, Baining Guo <Br>
[CVPR 2023] [[Pytorch-Code](https://github.com/researchmm/MM-Diffusion)] <Br>

- **GAN-Supervised Dense Visual Alignment** <Br>
[Sihyun Yu](https://sihyun.me/), [Kihyuk Sohn](https://sites.google.com/site/kihyuksml/), [Subin Kim](https://subin-kim-cv.github.io/), [Jinwoo Shin](https://alinlab.kaist.ac.kr/shin.html) <Br>
[CVPR 2023] [[Project](https://sihyun.me/PVDM/)] [[Pytorch-Code](https://github.com/sihyun-yu/PVDM)] <Br>

- **Conditional Image-to-Video Generation with Latent Flow Diffusion Models** <Br>
[Haomiao Ni](https://sites.google.com/view/haomiaoni/home), [Changhao Shi](https://www.changhaoshi.com/), [Kai Li](https://kailigo.github.io/), [Sharon X. Huang](http://faculty.ist.psu.edu/suh972/), [Martin Renqiang Min](https://www.cs.toronto.edu/~cuty/) <Br>
[CVPR 2023] [[Pytorch-Code](https://github.com/nihaomiao/CVPR23_LFDM)] <Br>

- **GAN-Supervised Dense Visual Alignment** <Br>
[William Peebles](https://www.wpeebles.com/), [Jun-Yan Zhu](https://www.cs.cmu.edu/~junyanz/), [Richard Zhang](http://richzhang.github.io/), [Antonio Torralba](https://groups.csail.mit.edu/vision/torralbalab/), [Alexei A. Efros](http://people.eecs.berkeley.edu/~efros/), [Eli Shechtman](https://research.adobe.com/person/eli-shechtman/) <Br>
[CVPR 2022 Oral] [[Project](https://www.wpeebles.com/gangealing)] [[Pytorch-Code](https://github.com/wpeebles/gangealing)] <Br>

- **Thin-Plate Spline Motion Model for Image Animation** <Br>
Jian Zhao, Hui Zhang <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/yoyo-nb/Thin-Plate-Spline-Motion-Model)] <Br>

- **Make It Move: Controllable Image-to-Video Generation with Text Descriptions** <Br>
Yaosi Hu, [Chong Luo](https://www.microsoft.com/en-us/research/people/cluo/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fpeople%2Fcluo%2F), Zhenzhong Chen<Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/Youncy-Hu/MAGE)] <Br>
[**MAGE**]

- **StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2** <Br>
[Ivan Skorokhodov](https://universome.github.io/), [Sergey Tulyakov](http://www.stulyakov.com/), [Mohamed Elhoseiny](http://www.mohamed-elhoseiny.com/) <Br>
[CVPR 2022] [[Project](https://universome.github.io/stylegan-v)] [[Pytorch-Code](https://github.com/universome/stylegan-v)] <Br>

- **Playable Environments: Video Manipulation in Space and Time** <Br>
[Willi Menapace](https://www.willimenapace.com/), [StÃ©phane LathuiliÃ¨re](https://stelat.eu/), [Aliaksandr Siarohin](https://github.com/AliaksandrSiarohin), [Christian Theobalt](https://www.mpg.de/16583907/informatics-theobalt), [Sergey Tulyakov](http://www.stulyakov.com/), [Vladislav Golyanik](https://people.mpi-inf.mpg.de/~golyanik/), [Elisa Ricci](http://elisaricci.eu/) <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/willi-menapace/PlayableEnvironments)] <Br>

- **Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning** <Br>
[Ligong Han](https://phymhan.github.io/), [Jian Ren](https://alanspike.github.io/), Hsin-Ying Lee, [Francesco Barbieri](https://fvancesco.github.io/), [Kyle Olszewski](https://kyleolsz.github.io/), [Shervin Minaee](https://sites.google.com/site/shervinminaee/home) <Br>
[CVPR 2022] [[Project](https://snap-research.github.io/MMVID/)] [[Pytorch-Code](https://github.com/snap-research/MMVID)] <Br>
[**MMVID**]

- **Attribute Group Editing for Reliable Few-shot Image Generation** <Br>
Guanqi Ding, Xinzhe Han, Shuhui Wang, Shuzhe Wu, Xin Jin, Dandan Tu, Qingming Huang <Br>
[CVPR 2022] [[Pytorch-Code](https://github.com/OpenTalker/DPE)] <Br>
[**AGE**]



# Video Editing
- **StableVideo: Text-driven Consistency-aware Diffusion Video Editing** <Br>
[Wenhao Chai](https://rese1f.github.io/), Xun Guoâœ‰ï¸, Gaoang Wang, Yan Lu <Br>
[ICCV 2023 Oral] [[Project](https://rese1f.github.io/StableVideo/)] [[Pytorch-Code](https://github.com/rese1f/StableVideo)] <Br>
ğŸ”¥

- **FateZero: Fusing Attentions for Zero-shot Text-based Video Editing** <Br>
[Chenyang Qi](https://chenyangqiqi.github.io/), [Xiaodong Cun](http://vinthony.github.io/), [Yong Zhang](https://yzhang2016.github.io), [Chenyang Lei](https://chenyanglei.github.io/), [Xintao Wang](https://xinntao.github.io/), [Ying Shan](https://scholar.google.com/citations?hl=zh-CN&user=4oXBp9UAAAAJ), [Qifeng Chen](https://cqf.io) <Br>
[ICCV 2023 Oral] [[Project](https://fate-zero-edit.github.io/)] [[Pytorch-Code](https://github.com/ChenyangQiQi/FateZero)] <Br>
ğŸ”¥

- **Shape-aware Text-driven Layered Video Editing** <Br>
[Yao-Chih Lee](https://yaochih.github.io/), Ji-Ze G. Jang, [Yi-Ting Chen](https://jamie725.github.io/website/), [Elizabeth Qiu](https://elizabethqiu.com/), [Jia-Bin Huang](https://jbhuang0604.github.io/) <Br>
[CVPR 2023] [[Project](https://text-video-edit.github.io/#)] [[Pytorch-Code](https://github.com/text-video-edit/shape-aware-text-driven-layered-video-editing-release)] <Br>

- **Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding** <Br>
Gyeongman Kim, Hajin Shim, [Hyunsu Kim](https://blandocs.github.io/), [Yunjey Choi](https://yunjey.github.io/), Junho Kim, Eunho Yang <Br>
[CVPR 2023] [[Project](https://diff-video-ae.github.io/)] [[Pytorch-Code](https://github.com/man805/Diffusion-Video-Autoencoders)] <Br>

- **DPE: Disentanglement of Pose and Expression for General Video Portrait Editing** <Br>
[Youxin Pang](https://carlyx.github.io/), [Yong Zhang](https://yzhang2016.github.io/), Weize Quan, [Yanbo Fan](https://sites.google.com/site/yanbofan0124/), [Xiaodong Cun](https://vinthony.github.io/academic/), Ying Shan, [Dong-ming Yan](https://sites.google.com/site/yandongming/) <Br>
[CVPR 2023] [[Project](https://carlyx.github.io/DPE/)] [[Pytorch-Code](https://github.com/UniBester/AGE)] <Br>



# Misc
- **AutoTransition: Learning to Recommend Video Transition Effects** <Br>
Yaojie Shen, Libo Zhang, Kai Xu, [Xiaojie Jin](https://airobotai.github.io/jinxiaojie/) <Br>
[ECCV 2022] [å­—èŠ‚è·³åŠ¨] [[Pytorch-Code](https://github.com/AcherStyx/AutoTransition)] <Br>
è‡ªåŠ¨ç”Ÿæˆå‰ªè¾‘

- **ClothFormer: Taming Video Virtual Try-on in All Module** <Br>
Jianbin Jiang, Tan Wang, He Yan, Junhui Liu <Br>
[CVPR 2022 Oral] [[Project](https://cloth-former.github.io/)] [[Pytorch-Code](https://github.com/luxiangju-PersonAI/ClothFormer)] <Br>

- **Real-time Localized Photorealistic Video Style Transfer** <Br>
[Xide Xia](https://xidexia.github.io/), [Tianfan Xue](https://tianfan.info/), [Wei-Sheng Lai](https://www.wslai.net/), Zheng Sun, Abby Chang, [Brian Kulis](http://people.bu.edu/bkulis/), [Jiawen Chen](http://people.csail.mit.edu/jiawen/)  <Br>
[WACV 2021] <Br>
[â˜…â˜…] åŸºäºHDRNetçš„è§†é¢‘style transfer.

- **Single-frame Regularization for Temporally Stable CNNs** <Br>
[Gabriel Eilertsen](https://liu.se/en/employee/gabei62), [RafaÅ‚ K. Mantiuk](https://www.cl.cam.ac.uk/~rkm38/), [Jonas Unger](https://weber.itn.liu.se/~jonun/web/Home.php) <Br>
[CVPR 2019] <Br>
[â˜…â˜†] æå‡ºå¢å¼ºè§†é¢‘å¸§é—´ç¨³å®šæ€§çš„ä¸€äº›æ­£åˆ™loss, åŒ…æ‹¬Stability regularization(åŠ å…¥é«˜æ–¯å™ªå£°), Transform invariance regularization(å‡ ä½•å˜æ¢), Sparse Jacobian regularization(æ¢¯åº¦ä¸€è‡´loss).

- **Blind Video Temporal Consistency** <Br>
[Nicolas Bonneel](https://perso.liris.cnrs.fr/nicolas.bonneel/), [James Tompkin](https://jamestompkin.com/), [Kalyan Sunkavalli](http://www.kalyans.org/), [Deqing Sun](https://deqings.github.io/), [Sylvain Paris](http://people.csail.mit.edu/sparis/), [Hanspeter Pfister](https://vcg.seas.harvard.edu/)  <Br>
[TOG 2015] [[Project](https://perso.liris.cnrs.fr/nicolas.bonneel/consistency/)] <Br>
[â˜…] å†…å®¹å’Œæ—¶åŸŸä¸€è‡´è”åˆæœ€å°åŒ–, é€‚ç”¨äºå„ç§å¤„ç†ç®—å­
